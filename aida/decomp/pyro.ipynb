{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyro\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.contrib.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, EmpiricalMarginal, TraceEnum_ELBO, config_enumerate, infer_discrete, Trace_ELBO\n",
    "import torch.distributions.constraints as constraints\n",
    "import torch.distributed as tdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2015-01-28    22761.0\n",
       "2015-02-28    24671.7\n",
       "2015-03-28    33396.9\n",
       "2015-04-28    34548.8\n",
       "2015-05-28    33666.1\n",
       "Name: sum, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/jq/software/triplet-all/monthly.csv')\n",
    "\n",
    "data['date'] = data[['month', 'year']].apply(lambda x: \"28-\"+str(int(x[0]))+'-'+str(int(x[1])), axis=1)\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data = data.sort_values(by='date')\n",
    "ser = data['sum']\n",
    "ser.index = data['date']\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions.torch_distribution import TorchDistributionMixin\n",
    "class Bernoulli(torch.distributions.Bernoulli, TorchDistributionMixin):\n",
    "    def expand(self, batch_shape):\n",
    "        validate_args = self.__dict__.get('validate_args')\n",
    "        if 'probs' in self.__dict__:\n",
    "            print(self.probs.shape)\n",
    "            probs = self.probs.expand(batch_shape)\n",
    "            print(probs.shape)\n",
    "            return Bernoulli(probs=probs, validate_args=validate_args)\n",
    "        else:\n",
    "            logits = self.logits.expand(batch_shape)\n",
    "            return Bernoulli(logits=logits, validate_args=validate_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyro.poutine.runtime import _MODULE_NAMESPACE_DIVIDER, _PYRO_PARAM_STORE, am_i_wrapped, apply_stack, effectful\n",
    "from pyro.poutine.subsample_messenger import SubsampleMessenger\n",
    "def sample1(name, fn, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Calls the stochastic function `fn` with additional side-effects depending\n",
    "    on `name` and the enclosing context (e.g. an inference algorithm).\n",
    "    See `Intro I <http://pyro.ai/examples/intro_part_i.html>`_ and\n",
    "    `Intro II <http://pyro.ai/examples/intro_part_ii.html>`_ for a discussion.\n",
    "\n",
    "    :param name: name of sample\n",
    "    :param fn: distribution class or function\n",
    "    :param obs: observed datum (optional; should only be used in context of\n",
    "        inference) optionally specified in kwargs\n",
    "    :param dict infer: Optional dictionary of inference parameters specified\n",
    "        in kwargs. See inference documentation for details.\n",
    "    :returns: sample\n",
    "    \"\"\"\n",
    "    obs = kwargs.pop(\"obs\", None)\n",
    "    infer = kwargs.pop(\"infer\", {}).copy()\n",
    "    # check if stack is empty\n",
    "    # if stack empty, default behavior (defined here)\n",
    "    if not am_i_wrapped():\n",
    "        if obs is not None:\n",
    "            warnings.warn(\"trying to observe a value outside of inference at \" + name,\n",
    "                          RuntimeWarning)\n",
    "            return obs\n",
    "        return fn(*args, **kwargs)\n",
    "    # if stack not empty, apply everything in the stack?\n",
    "    else:\n",
    "        # initialize data structure to pass up/down the stack\n",
    "        msg = {\n",
    "            \"type\": \"sample\",\n",
    "            \"name\": name,\n",
    "            \"fn\": fn,\n",
    "            \"is_observed\": False,\n",
    "            \"args\": args,\n",
    "            \"kwargs\": kwargs,\n",
    "            \"value\": None,\n",
    "            \"infer\": infer,\n",
    "            \"scale\": 1.0,\n",
    "            \"mask\": None,\n",
    "            \"cond_indep_stack\": (),\n",
    "            \"done\": False,\n",
    "            \"stop\": False,\n",
    "            \"continuation\": None\n",
    "        }\n",
    "        # handle observation\n",
    "        if obs is not None:\n",
    "            msg[\"value\"] = obs\n",
    "            msg[\"is_observed\"] = True\n",
    "        # apply the stack and return its return value\n",
    "        apply_stack(msg)\n",
    "        print(msg)\n",
    "        return msg[\"value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decompose:\n",
    "    \n",
    "    def __init__(self, series, monthly=True, is_sub = False):\n",
    "        assert monthly\n",
    "        if monthly:\n",
    "            self.target = torch.tensor(series.values[2:], device=device, dtype = torch.float32)\n",
    "            \n",
    "        \n",
    "            months = series.index.month-1\n",
    "            \n",
    "            self.month_vals = torch.tensor(np.zeros((len(self.target), 12), dtype = np.float32), device=device)\n",
    "            months = months[2:]\n",
    "            for i, m in enumerate(months):\n",
    "                self.month_vals[i, m] = 1.0\n",
    "            self.slopes = torch.tensor(series.values[1:-1]-series.values[:-2], dtype = torch.float32).to(device)\n",
    "\n",
    "            self.last_levels = torch.tensor(series.values[1:-1], dtype = torch.float32).to(device)\n",
    "\n",
    "        pyro.clear_param_store()\n",
    "        self.is_sub = is_sub\n",
    "        self.create_guide()\n",
    "        self.svi_create()\n",
    "    @config_enumerate    \n",
    "    def model(self, ser, months, slopes, last_levels):\n",
    "        mu = torch.zeros(12)\n",
    "        seasonal_weights = pyro.sample('seas_weights', dist.MultivariateNormal(mu, torch.eye(12)))\n",
    "        alpha0 = torch.ones(ser.shape[0], dtype=torch.float32)*4.0\n",
    "        beta0 = torch.ones(ser.shape[0], dtype=torch.float32)*4.0\n",
    "        #with pyro.plate('observe', len(ser)):\n",
    "        for i in range(len(ser)):\n",
    "            trend1 = pyro.sample('trend1_{}'.format(i), dist.Normal(1, 0.5))\n",
    "            trend2 = pyro.sample('trend2_{}'.format(i), dist.Normal(0, 5))\n",
    "            mix_flip = pyro.sample(\"mix_flip_{}\".format(i), dist.Beta(alpha0[i], beta0[i]))\n",
    "            p = pyro.sample('p_{}'.format(i), dist.Bernoulli(mix_flip))\n",
    "            decomp = months[i, :]@seasonal_weights+(1-p)*trend1*slopes[i]+p*trend2+last_levels[i]\n",
    "            \n",
    "            res = ser[i]-decomp\n",
    "            pyro.sample('residuals_obs_{}'.format(i), dist.Normal(0, 2), obs=res)\n",
    "    @config_enumerate    \n",
    "    def model_fucked(self, ser, months, slopes, last_levels):\n",
    "        \n",
    "        mu = torch.zeros(12)\n",
    "        seasonal_weights = pyro.sample('seas_weights', dist.MultivariateNormal(mu, torch.eye(12)))\n",
    "        \n",
    "        \n",
    "        with pyro.plate('flip', len(ser)):\n",
    "            alpha0 = pyro.param('alpha0', torch.ones(ser.shape[0], dtype=torch.float32)*4.0)\n",
    "            beta0 = pyro.param('beta0',torch.ones(ser.shape[0], dtype=torch.float32)*4.0)\n",
    "            mix_flip = pyro.sample(\"mix_flip\", dist.Beta(alpha0, beta0))\n",
    "            p = sample1('p', Bernoulli(probs=mix_flip))\n",
    "            print(p.size())\n",
    "            print(mix_flip.size())\n",
    "            assert p.size() == mix_flip.size()\n",
    "            \n",
    "        \n",
    "        with pyro.plate('observe', len(ser)):\n",
    "            print(p.size())\n",
    "            #assert False\n",
    "            trend1 = pyro.sample('trend1', dist.Normal(1, 0.5))\n",
    "            trend2 = pyro.sample('trend2', dist.Normal(0, 5))\n",
    "            \n",
    "            decomp = months@torch.t(seasonal_weights)+(1-p)*trend1*slopes+p*trend2+last_levels\n",
    "            \n",
    "            res = ser-decomp\n",
    "            pyro.sample('residuals_obs', dist.Normal(0, 2), obs=res)\n",
    "    \n",
    "    def guide_old(self, ser, months, slopes, last_levels):\n",
    "        mu = pyro.sample('mu',dist.MultivariateNormal(torch.zeros(12), torch.eye(12)))\n",
    "        aa = torch.ones(ser.shape[0], dtype=torch.float32)*5.0\n",
    "        bb = torch.ones(ser.shape[0], dtype=torch.float32)*5.0\n",
    "        alpha_q = pyro.param('alpha_q', aa, constraint=constraints.positive)\n",
    "        beta_q = pyro.param('beta_q', bb, constraint=constraints.positive)\n",
    "        pyro.sample('seas_weights', dist.MultivariateNormal(mu, torch.eye(12)))\n",
    "        for i in range(len(ser)):\n",
    "            pyro.sample(\"mix_flip_{}\".format(i), dist.Beta(alpha_q[i], beta_q[i]))\n",
    "    \n",
    "    def create_guide_old(self):\n",
    "        \n",
    "        expose = ['mix_flip_{}'.format(i) for i in range(len(self.target))] \n",
    "        #expose.extend(['p_{}'.format(i) for i in range(len(self.target))])\n",
    "        expose.extend(['trend1_{}'.format(i) for i in range(len(self.target))])\n",
    "        expose.extend(['trend2_{}'.format(i) for i in range(len(self.target))])\n",
    "        expose.extend(['resid_obs_{}'.format(i) for i in range(len(self.target))])\n",
    "        \n",
    "        self.guide = AutoDelta(poutine.block(self.model, expose=expose))\n",
    "    def create_guide(self):\n",
    "        \n",
    "        expose = ['mix_flip', 'trend1', 'trend2', 'resid_obs', 'alpha0', 'beta0']\n",
    "        \n",
    "        self.guide = config_enumerate(AutoDelta(poutine.block(self.model, expose=expose)))\n",
    "    \n",
    "    def svi_create(self):\n",
    "        adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "        self.optimizer = Adam(adam_params)\n",
    "        self.svi = SVI(self.model, self.guide, self.optimizer, loss = TraceEnum_ELBO(max_plate_nesting=0))\n",
    "    \n",
    "    def step_once(self):\n",
    "        return self.svi.step(self.target, self.month_vals, self.slopes, self.last_levels)\n",
    "    \n",
    "    def posterior(self):\n",
    "        return self.svi.run(self.target, self.month_vals, self.slopes, self.last_levels)\n",
    "    \n",
    "#     def get_ps(self, i):\n",
    "#         return pyro.param('mix_flip_{}'.format(i)).item()\n",
    "    \n",
    "    def get_estimates(self):\n",
    "        return self.guide(self.target, self.month_vals, self.slopes, self.last_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = Decompose(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238122763.30666664"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_ave = 0.0\n",
    "for s in range(300):\n",
    "    a = dd.step_once()\n",
    "    loss_ave += a/300\n",
    "loss_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = dd.posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyro.infer.svi.SVI at 0x7f1971c8f320>"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_base = ['mix_flip_{}', 'trend1_{}', 'trend2_{}']\n",
    "sites = [s.format(i) for s in sites_base for i in range(len(dd.target))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['alpha_q', 'beta_q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_methods = [method_name for method_name in dir(pp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_categorical',\n",
       " '_idx_by_chain',\n",
       " '_reset',\n",
       " '_traces',\n",
       " 'chain_ids',\n",
       " 'evaluate_loss',\n",
       " 'exec_traces',\n",
       " 'guide',\n",
       " 'information_criterion',\n",
       " 'log_weights',\n",
       " 'loss',\n",
       " 'loss_and_grads',\n",
       " 'marginal',\n",
       " 'model',\n",
       " 'num_chains',\n",
       " 'num_samples',\n",
       " 'num_steps',\n",
       " 'optim',\n",
       " 'run',\n",
       " 'step']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        \n",
    "        site_stats[site_name] = marginal_site.values[-1, 0]\n",
    "        assert marginal_site.shape[1]==1\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['mix_flip_{}'.format(i) for i in range(len(dd.target))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: mix_flip_0\n",
      "0.34144285 \n",
      "\n",
      "Site: mix_flip_1\n",
      "0.2563037 \n",
      "\n",
      "Site: mix_flip_2\n",
      "0.62575907 \n",
      "\n",
      "Site: mix_flip_3\n",
      "0.5846108 \n",
      "\n",
      "Site: mix_flip_4\n",
      "0.24605341 \n",
      "\n",
      "Site: mix_flip_5\n",
      "0.8712591 \n",
      "\n",
      "Site: mix_flip_6\n",
      "0.5724141 \n",
      "\n",
      "Site: mix_flip_7\n",
      "0.8566051 \n",
      "\n",
      "Site: mix_flip_8\n",
      "0.37586063 \n",
      "\n",
      "Site: mix_flip_9\n",
      "0.5974249 \n",
      "\n",
      "Site: mix_flip_10\n",
      "0.469811 \n",
      "\n",
      "Site: mix_flip_11\n",
      "0.65127206 \n",
      "\n",
      "Site: mix_flip_12\n",
      "0.5302198 \n",
      "\n",
      "Site: mix_flip_13\n",
      "0.39007226 \n",
      "\n",
      "Site: mix_flip_14\n",
      "0.39747983 \n",
      "\n",
      "Site: mix_flip_15\n",
      "0.37836918 \n",
      "\n",
      "Site: mix_flip_16\n",
      "0.50440305 \n",
      "\n",
      "Site: mix_flip_17\n",
      "0.57412404 \n",
      "\n",
      "Site: mix_flip_18\n",
      "0.5448409 \n",
      "\n",
      "Site: mix_flip_19\n",
      "0.5623941 \n",
      "\n",
      "Site: mix_flip_20\n",
      "0.5257955 \n",
      "\n",
      "Site: mix_flip_21\n",
      "0.52102786 \n",
      "\n",
      "Site: mix_flip_22\n",
      "0.70737034 \n",
      "\n",
      "Site: mix_flip_23\n",
      "0.47388557 \n",
      "\n",
      "Site: mix_flip_24\n",
      "0.6361213 \n",
      "\n",
      "Site: mix_flip_25\n",
      "0.54187626 \n",
      "\n",
      "Site: mix_flip_26\n",
      "0.10781257 \n",
      "\n",
      "Site: mix_flip_27\n",
      "0.42253318 \n",
      "\n",
      "Site: mix_flip_28\n",
      "0.70721716 \n",
      "\n",
      "Site: mix_flip_29\n",
      "0.30327514 \n",
      "\n",
      "Site: mix_flip_30\n",
      "0.8665507 \n",
      "\n",
      "Site: mix_flip_31\n",
      "0.2591121 \n",
      "\n",
      "Site: mix_flip_32\n",
      "0.3933496 \n",
      "\n",
      "Site: mix_flip_33\n",
      "0.7167753 \n",
      "\n",
      "Site: mix_flip_34\n",
      "0.33874837 \n",
      "\n",
      "Site: mix_flip_35\n",
      "0.4668886 \n",
      "\n",
      "Site: mix_flip_36\n",
      "0.6240414 \n",
      "\n",
      "Site: mix_flip_37\n",
      "0.4601707 \n",
      "\n",
      "Site: mix_flip_38\n",
      "0.72009444 \n",
      "\n",
      "Site: mix_flip_39\n",
      "0.71195436 \n",
      "\n",
      "Site: mix_flip_40\n",
      "0.28553703 \n",
      "\n",
      "Site: mix_flip_41\n",
      "0.58138597 \n",
      "\n",
      "Site: mix_flip_42\n",
      "0.5887723 \n",
      "\n",
      "Site: mix_flip_43\n",
      "0.2651948 \n",
      "\n",
      "Site: mix_flip_44\n",
      "0.267434 \n",
      "\n",
      "Site: mix_flip_45\n",
      "0.32946223 \n",
      "\n",
      "Site: mix_flip_46\n",
      "0.2894807 \n",
      "\n",
      "Site: mix_flip_47\n",
      "0.404839 \n",
      "\n",
      "Site: mix_flip_48\n",
      "0.54046077 \n",
      "\n",
      "Site: mix_flip_49\n",
      "0.579566 \n",
      "\n",
      "Site: mix_flip_50\n",
      "0.4473076 \n",
      "\n",
      "Site: mix_flip_51\n",
      "0.6591175 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "svi_samples = {site: EmpiricalMarginal(pp, sites=site)\n",
    "                     .enumerate_support().detach().cpu().numpy()\n",
    "               for site in sites}\n",
    "\n",
    "for site, values in last(svi_samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecomposeTorch(nn.Module):\n",
    "    \n",
    "    def __init__(self, series, monthly=True, is_sub = False):\n",
    "        super().__init__()\n",
    "        assert monthly\n",
    "        if monthly:\n",
    "            self.target = torch.tensor(series.values[2:], device=device, dtype = torch.float32)\n",
    "            months = series.index.month-1\n",
    "            \n",
    "            self.month_vals = torch.tensor(np.zeros((len(self.target), 12), dtype = np.float32), device=device)\n",
    "            months = months[2:]\n",
    "            for i, m in enumerate(months):\n",
    "                self.month_vals[i, m] = 1.0\n",
    "            self.slopes = torch.tensor(series.values[1:-1]-series.values[:-2], dtype = torch.float32).to(device)\n",
    "            self.last_levels = torch.tensor(series.values[1:-1], dtype = torch.float32).to(device)\n",
    "        self.is_sub = is_sub\n",
    "        self.seasonal = nn.Linear(12, 1)\n",
    "        self.ps = nn.Parameter(torch.zeros(len(self.target), dtype = torch.float32)).to(device)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.03)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, ser, months, slopes, last_levels):\n",
    "        seas = self.seasonal(months)\n",
    "        self.ps.data = torch.clamp(self.ps, 0, 1)\n",
    "        trend = slopes*(1-self.ps)+self.ps*last_levels\n",
    "        \n",
    "        resid = ser - seas - trend\n",
    "        self.ps.data = torch.clamp(self.ps, 0, 1)\n",
    "        return trend, seas, resid\n",
    "        \n",
    "    \n",
    "    def step_once(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        trend, seas, resid = self.forward(self.target, self.month_vals, self.slopes, self.last_levels)\n",
    "        ls = torch.sum(resid**2)\n",
    "        ls.backward()\n",
    "        self.optimizer.step()\n",
    "        return ls.item(), trend, seas, resid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = DecomposeTorch(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5410579787475.656"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_ave = 0.0\n",
    "for s in range(30000):\n",
    "    a, tr, se, re = de.step_once()\n",
    "    loss_ave += a/300\n",
    "loss_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0297, 0.9793, 0.9212, 1.0297, 0.9831, 0.9831, 1.0294, 0.8262, 0.9549,\n",
       "        1.0296, 0.6825, 0.9534, 1.0298, 0.9330, 1.0293, 1.0297, 0.6967, 1.0298,\n",
       "        0.9352, 0.7556, 0.9609, 0.9917, 0.8103, 0.8689, 1.0298, 0.7652, 1.0298,\n",
       "        0.9680, 0.9756, 1.0293, 0.9858, 0.8338, 0.9016, 0.9125, 0.9746, 0.8924,\n",
       "        1.0298, 0.9609, 1.0298, 0.8042, 1.0295, 1.0296, 0.7926, 1.0284, 0.8709,\n",
       "        0.9080, 0.9446, 0.9102, 1.0295, 1.0298, 1.0294, 0.8206],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de.ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11403.4062, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24671.6992, 32834.7109, 31947.4199, 33666.1016, 39855.9922, 40890.7617,\n",
       "        42609.5000, 39890.9180, 39435.1055, 41284.3984, 34009.7773, 33533.1367,\n",
       "        35252.5000, 45858.6641, 47591.6016, 51948.0000, 43287.8789, 45006.1992,\n",
       "        52507.8750, 40882.0391, 40273.7891, 41613.0156, 35387.5000, 31444.1523,\n",
       "        33141.3008, 34925.5391, 36649.8984, 45183.0000, 45777.9141, 47496.3008,\n",
       "        51218.6797, 44278.3828, 40793.5156, 38491.3516, 39133.6836, 36635.1367,\n",
       "        38363.1016, 47115.4102, 48834.1992, 49390.1484, 51109.3008, 56538.3008,\n",
       "        50950.5859, 52669.3984, 48640.2539, 45241.0430, 44172.8320, 41678.5703,\n",
       "        43395.5000, 48742.1016, 60721.1992, 54245.4844],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
